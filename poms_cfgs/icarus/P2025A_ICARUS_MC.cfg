# test config for gen in ICARUS experiment
[global]
#
# This section has variables we use later in the file as %(name)s
#
group      = icarus
experiment = icarus
wrapper = file:///${FIFE_UTILS_DIR}/libexec/fife_wrap
#override on command line with proper sw. version
version = v08_56_00 
# override on command line with proper qualifiers
quals   = e20:prof

# overridden in --stage sections (below)
basename = gen
# usually overridden on command line with poms
sam_dataset = override_me_sam_dataset

# generic fcl file names
fclfile0 = override_me_0
fclfile1 = override_me_1
fclfile2 = override_me_2
fclfile3 = override_me_3
fclfile4 = override_me_4

wrapperfclfile0 = wrapper_%(fclfile0)s
wrapperfclfile1 = wrapper_%(fclfile1)s
wrapperfclfile2 = wrapper_%(fclfile2)s
wrapperfclfile3 = wrapper_%(fclfile3)s
wrapperfclfile4 = wrapper_%(fclfile4)s


#setupwrapperfile = icaruspoms_wrapper_fclmaker.sh
setupwrapperfile = sbnpoms_wrapperfcl_maker.sh

#larsoft file processing stages to run
stagename0 = name0
stagename1 = name1
stagename2 = name2
stagename3 = name3
stagename4 = name4

# Campaign Information
#prodtype = production/test
output_filename = override_me_output_filename
prodtype = test
filetype = mc

campaign = 2022A_00
sample = single_electron_bnb

# Destination Folder Structure

sbndatapool = data_add
dataset_name_struct = %(prodtype)s_%(filetype)s_%(campaign)s_%(sample)s_%(version)s

dest_struct = %(filetype)s/%(campaign)s/%(sample)s/%(version)s

data_dest = /pnfs/sbn/%(sbndatapool)s/sbn_fd/poms_%(prodtype)s/%(dest_struct)s
scratch_dest = /pnfs/%(experiment)s/scratch/users/%(experiment)spro/poms_%(prodtype)s/%(dest_struct)s

#Number of events per job
nevt=-1
# overridden in --stage sections (below) or on cmd line
# for merge passes, override on command line

#run,subrun,event
firstrun = 1
first_subrun = \${PROCESS}
first_enum = \$\(\(PROCESS*%(nevt)s+1\)\)
first_event = %(firstrun)s:%(first_subrun)s:%(first_enum)s
fclfilename0 = override_me_fclfilename0

stage_name = gen

##Metadata##
streamname = override_me_streamname

#Variables to be deleted
last_stage = override_me_last_stage


[env_pass]
#
# these become -e parameters to jobsub_submit
#
IFDH_DEBUG = 1
#SAM_EXPERIMENT=%(experiment)s
SAM_EXPERIMENT=sbn
#SAM_GROUP=%(group)s
SAM_GROUP=sbn
#SAM_STATION=%(experiment)s
SAM_STATION=sbn
SAM_WEB_HOST = samsbn.fnal.gov
IFDH_BASE_URI=http://samsbn.fnal.gov:8480/sam/sbn/api/
#ARTROOT_DATASET = %(artRoot_dataset)s
#HISTROOT_DATASET = %(histRoot_dataset)s
IFDH_TOKEN_ENABLE=1
IFDH_PROXY_ENABLE=0
LC_ALL=C

[submit]
#
# these become options to jobsub_submit
#
G          = %(group)s
N          = 5
dataset     =
resource-provides      = usage_model=OPPORTUNISTIC,DEDICATED,OFFSITE
generate-email-summary = True
expected-lifetime      = 4h
timeout                = 3h
disk                  = 50GB
memory                 = 2000MB
f_0                    = /pnfs/icarus/resilient/icaruspro/poms_scripts/icaruspoms_tfilemetadata_extractor.sh
#f_0                    = /pnfs/icarus/resilient/icaruspro/poms_scripts/%(setupwrapperfile)s 
#f_1                    = /pnfs/icarus/resilient/icaruspro/poms_scripts/icaruspoms_runnumber_injector.sh 
#f_2                    = /pnfs/icarus/resilient/icaruspro/poms_scripts/icaruspoms_metadata_injector.sh
append_condor_requirements = '((TARGET.has_avx==true)&&(TARGET.HAS_CVMFS_icarus_opensciencegrid_org==true))&&(TARGET.HAS_SINGULARITY=?=true)'
lines_1                = '+SingularityImage=\"/cvmfs/singularity.opensciencegrid.org/fermilab/fnal-wn-sl7:latest\"'
lines_2                = '+FERMIHTC_AutoRelease=True'
lines_3                = '+FERMIHTC_GraceMemory=3000'
lines_4                = '+FERMIHTC_GraceLifetime=7200'
subgroup               = pro
blacklist              = RAL

#append_condor_requirements = ((TARGET.has_avx==true)&&(TARGET.HAS_CVMFS_icarus_opensciencegrid_org==true))
#line_1 = +PeriodicRemove=JobStatus==5&&HoldReasonCode==26&&CurrentTime-EnteredCurrentStatus>3600
#tar_file_name     = /pnfs/icarus/resilient/icaruspro/local_08_57_00.tar

[job_setup]
#
# these are options to fife_wrap about setting up the job environment,
# and main execution loop
#
debug        = True
find_setups  = True
setup_local  = True
source_0     = /cvmfs/%(experiment)s.opensciencegrid.org/products/%(experiment)s/setup_%(experiment)s.sh
setup_0      = %(experiment)scode %(version)s -q %(quals)s
setup_1      = sbnutil -q sbn
prescript_0  = export FW_SEARCH_PATH=$FW_SEARCH_PATH:$CONDOR_DIR_INPUT
prescript_1  = export FHICL_FILE_PATH=$FHICL_FILE_PATH:$CONDOR_DIR_INPUT
multifile    = False

[sam_consumer]
#
# parameters to SAM / ifdh establishProcess
#
limit       = 1
appvers     = %(version)s
appfamily   = art
appname     = %(stage_name)s
#schema     = gsiftp
schema      = root

[executable]
#
# parameters to main executable in job
#
name       = lar
arg_1      = -c
arg_2      = \$CONDOR_DIR_INPUT/%(wrapperfclfile0)s
arg_3      = -o
arg_4      = %%ifb_%%tc_%(basename)s.root
arg_5      = -T 
arg_6      = hist_%%ifb_%%tc_%(basename)s.root
arg_7      = -n 
arg_8      = %(nevt)s 
arg_9      = --sam-data-tier
arg_10     = simulation
arg_11     = --sam-stream-name
arg_12     = out1
arg_13     = -s
arg_14     = 

[executable_1]
#
# parameters to main executable in job
#
name       = true
arg_1      = -c
arg_2      = %(fclfile1)s
arg_3      = -o
arg_4      = %(basename)s_\${CLUSTER}_\${PROCESS}.root
arg_5      = -T 
arg_6      = hist_%(basename)s_\${CLUSTER}_\${PROCESS}.root
arg_7      = -n 
arg_8      = %(nevt)s 
arg_9      = --sam-data-tier
arg_10     = simulation
arg_11     = --sam-stream-name
arg_12     = out1
arg_13     = -s
arg_14     = input_filename -- will be added by multifile loop...

[executable_2]
#
# parameters to main executable in job
#
name       = true
arg_1      = -c
arg_2      = %(fclfile2)s
arg_3      = -o
arg_4      = %(basename)s_\${CLUSTER}_\${PROCESS}.root
arg_5      = -T 
arg_6      = hist_%(basename)s_\${CLUSTER}_\${PROCESS}.root
arg_7      = -n 
arg_8      = %(nevt)s 
arg_9      = --sam-data-tier
arg_10     = simulation
arg_11     = --sam-stream-name
arg_12     = out1
arg_13     = -s
arg_14     = input_filename -- will be added by multifile loop...

[executable_3]
#
# parameters to main executable in job
#
name       = true
arg_1      = -c
arg_2      = %(fclfile3)s
arg_3      = -o
arg_4      = %(basename)s_\${CLUSTER}_\${PROCESS}.root
arg_5      = -T 
arg_6      = hist_%(basename)s_\${CLUSTER}_\${PROCESS}.root
arg_7      = -n 
arg_8      = %(nevt)s 
arg_9      = --sam-data-tier
arg_10     = simulation
arg_11     = --sam-stream-name
arg_12     = out1
arg_13     = -s
arg_14     = input_filename -- will be added by multifile loop...

[executable_4]
#
# parameters to main executable in job
#
name       = true
arg_1      = -c
arg_2      = %(fclfile4)s
arg_3      = -o
arg_4      = %(basename)s_\${CLUSTER}_\${PROCESS}.root
arg_5      = -T 
arg_6      = hist_%(basename)s_\${CLUSTER}_\${PROCESS}.root
arg_7      = -n 
arg_8      = %(nevt)s 
arg_9      = --sam-data-tier
arg_10     = simulation
arg_11     = --sam-stream-name
arg_12     = out1
arg_13     = -s
arg_14     = input_filename -- will be added by multifile loop...

[executable_5]
#
# parameters to main executable in job
#
name       = true
arg_1      = -c
arg_2      = %(fclfile4)s
arg_3      = -o
arg_4      = %(basename)s_\${CLUSTER}_\${PROCESS}.root
arg_5      = -T 
arg_6      = hist_%(basename)s_\${CLUSTER}_\${PROCESS}.root
arg_7      = -n 
arg_8      = %(nevt)s 
arg_9      = --sam-data-tier
arg_10     = simulation
arg_11     = --sam-stream-name
arg_12     = out1
arg_13     = -s
arg_14     = input_filename -- will be added by multifile loop...

[job_output]
#
# parameters to output handling section of fife_wrap
#
rename      = unique
addoutput   = *.[ol][ou][gt]
add_location = False       
dest        = /pnfs/%(experiment)s/scratch/users/%(experiment)spro/dropbox/mc1/dropbox/mc1/logs/
hash 	    = 2

[job_output_1]
#
# parameters to output handling section of fife_wrap
#
rename      = unique
addoutput   = *.[ol][ou][gt]
add_location = False       
dest        = /pnfs/%(experiment)s/scratch/users/%(experiment)spro/dropbox/mc1/dropbox/mc1/logs/
hash 	    = 2

[job_output_2]
#
# parameters to output handling section of fife_wrap
#
rename      = unique
addoutput   = *.[ol][ou][gt]
add_location = False
dest        = /pnfs/%(experiment)s/scratch/users/%(experiment)spro/dropbox/mc1/dropbox/mc1/logs/
hash 	    = 2

[job_output_3]
addoutput   = hist*%(basename)s*.root
rename      = unique
dest        = /pnfs/%(experiment)s/scratch/users/%(experiment)spro/dropbox/mc1/dropbox/mc1/poms_test/maya_test
declare_metadata = True
metadata_extractor = sam_metadata_dumper
hash 	    = 2

[job_output_4]
addoutput    = Suppl*.root
dest         = /pnfs/%(experiment)s/scratch/users/%(experiment)spro/dropbox/mc1/dropbox/mc1/poms_test/maya_test
metadata_extractor = sam_metadata_dumper
add_location = True
hash         = 2

[job_output_5]
addoutput    = Suppl*.root
dest         = /pnfs/%(experiment)s/scratch/users/%(experiment)spro/dropbox/mc1/dropbox/mc1/poms_test/maya_test
add_location = True
metadata_extractor = sam_metadata_dumper
hash         = 2

[job_output_6]
addoutput    = Suppl*.root
dest         = /pnfs/%(experiment)s/scratch/users/%(experiment)spro/dropbox/mc1/dropbox/mc1/poms_test/maya_test
add_location = True
metadata_extractor = sam_metadata_dumper
hash         = 2


#
# now we have overides for each processing stage/job type 
#
# you may need to change the global.fclfile overrides for each
# stage to reflect your experiment's naming convention for .fcl files
#

[stage_gen_g4]

env_pass.IFDH_FORCE = https
env_pass.IFDH_CP_MAXRETRIES = 5
env_pass.IFDH_HTTPS_EXTRA = -f

sam_consumer.limit = 1
job_setup.ifdh_art = False
job_setup.multifile = False
submit.append_condor_requirements = '(CVMFS_sbn_osgstorage_org_REVISION>=142423)'

global.fcl_list = %(fclfile0)s/%(fclfile1)s
global.basename = %(fclfilename0)s
global.stage_name = %(stagename0)s_%(stagename1)s

#Prescripts
job_setup.prescript_2  = sh sbnpoms_wrapperfcl_maker.sh --fclname %(fclfile0)s --wrappername $CONDOR_DIR_INPUT/%(wrapperfclfile0)s
job_setup.prescript_3  = sh sbnpoms_wrapperfcl_maker.sh --fclname %(fclfile1)s --wrappername $CONDOR_DIR_INPUT/%(wrapperfclfile1)s
job_setup.prescript_4   = cat $CONDOR_DIR_INPUT/%(wrapperfclfile0)s
job_setup.prescript_5   = cat $CONDOR_DIR_INPUT/%(wrapperfclfile1)s
job_setup.prescript_6  = sh sbnpoms_runnumber_injector.sh --fcl $CONDOR_DIR_INPUT/%(wrapperfclfile0)s --run %(firstrun)s --subruns_per_run 10 --process ${JOBSUBJOBSECTION}
job_setup.prescript_7  = sh sbnpoms_flux_injector.sh --fcl $CONDOR_DIR_INPUT/%(wrapperfclfile0)s
job_setup.prescript_8  = sh sbnpoms_metadata_injector.sh --inputfclname $CONDOR_DIR_INPUT/%(wrapperfclfile0)s --mdfclname %(fclfile0)s --mdprojectname %(campaign)s --mdprojectstage  %(stage_name)s --mdprojectversion %(version)s --mdprojectsoftware %(experiment)scode --mdproductionname %(sample)s --mdproductiontype %(prodtype)s --mdappversion %(version)s --mdfiletype %(filetype)s --mdappfamily art --mdruntype physics --mdgroupname %(experiment)s
job_setup.prescript_9  = sh sbnpoms_metadata_injector.sh --inputfclname $CONDOR_DIR_INPUT/%(wrapperfclfile1)s --mdfclname %(fcl_list)s --mdprojectname %(campaign)s --mdprojectstage %(stage_name)s --mdprojectversion %(version)s --mdprojectsoftware %(experiment)scode --mdproductionname %(sample)s --mdproductiontype %(prodtype)s --mdappversion %(version)s --mdfiletype %(filetype)s --mdappfamily art --mdruntype physics --mdgroupname %(experiment)s
job_setup.prescript_10 = echo "This PROCESS is ${PROCESS}"
job_setup.prescript_11 = echo "This JOBSUBJOBSECTION is ${JOBSUBJOBSECTION}"

##Postcripts
job_setup.postscript = ls -ltrh
job_setup.postscript_1 = echo "=========================="
job_setup.postscript_2 = cat $CONDOR_DIR_INPUT/%(wrapperfclfile0)s
job_setup.postscript_3 = echo "=========================="
job_setup.postscript_4 = cat %(fclfile0)s
job_setup.postscript_5 = echo "=========================="
job_setup.postscript_6 = cat $CONDOR_DIR_INPUT/%(wrapperfclfile1)s
job_setup.postscript_7 = du -h
job_setup.postscript_8 = echo "This PROCESS is ${PROCESS}"
job_setup.postscript_9 = echo "This JOBSUBJOBSECTION is ${JOBSUBJOBSECTION}"

####Executables

##Executable0##
executable.name = lar
executable.arg_1 = -c
executable.arg_2 = \$CONDOR_DIR_INPUT/%(wrapperfclfile0)s
executable.arg_3 = -o
executable.arg_4 = %(basename)s_%(stagename0)s_\${CLUSTER}_\${JOBSUBJOBSECTION}.root
executable.arg_5 = -T
executable.arg_6 = hist_%(basename)s_%(stagename0)s_\${CLUSTER}_\${JOBSUBJOBSECTION}.root
executable.arg_7 = -n
executable.arg_8 = %(nevt)s
executable.arg_9 = --sam-data-tier
executable.arg_10 = %(stagename0)s
executable.arg_11 = --sam-stream-name
executable.arg_12 = %(streamname)s
executable.arg_13 = 
executable.arg_14 = 

##Executable1##
executable_1.name = lar
executable_1.arg_1 = -c
executable_1.arg_2 = \$CONDOR_DIR_INPUT/%(wrapperfclfile1)s
executable_1.arg_3 = -s
executable_1.arg_4 = %(basename)s_gen_\${CLUSTER}_\${JOBSUBJOBSECTION}.root
executable_1.arg_5 = -o
executable_1.arg_6 = %(basename)s_%(stagename1)s_\${CLUSTER}_\${JOBSUBJOBSECTION}.root
executable_1.arg_7 = -T
executable_1.arg_8 = hist_%(basename)s_%(stagename1)s_\${CLUSTER}_\${JOBSUBJOBSECTION}.root
executable_1.arg_9 = -n
executable_1.arg_10 = %(nevt)s
executable_1.arg_11 = --sam-data-tier
executable_1.arg_12 = %(stagename1)s
executable_1.arg_13 = --sam-stream-name
executable_1.arg_14 = %(streamname)s

####Job Output#####
##Joboutput0##
job_output.declare_metadata = True
job_output.metadata_extractor = sam_metadata_dumper
job_output.add_location = True       
job_output.hash = 2
job_output.add_to_dataset = %(dataset_name_struct)s_%(stagename1)s
job_output.dataset_exclude = hist*
job_output.rename = unique
job_output.filter_metadata_1 = parents
job_output.addoutput = %(basename)s_%(stagename1)s_\${CLUSTER}_\${JOBSUBJOBSECTION}.root
job_output.dest = %(scratch_dest)s/%(stagename1)s/


[stage_detsim_stage0_stage1_caf]

#submit.tar_file_name     = dropbox:///pnfs/icarus/resilient/icaruspro/GridFiles/mpvmpr_Pi0_MopUp_v09_89_01_01p03.tar
#submit.tar_file_name     = dropbox:///pnfs/icarus/resilient/icaruspro/GridFiles/MopUpStudies_v09_89_01_01p02.tar
submit.cpu = 2
sam_consumer.limit = 1
job_setup.setup_2  = jemalloc v5_3_0b -q %(quals)s
job_setup.ifdh_art = False
job_setup.multifile = True
submit.dataset = %(sam_dataset)s
global.basename = %(fclfilename0)s
global.stage_name = %(stagename0)s_%(stagename1)s_%(stagename2)s_%(stagename3)s
global.fcl_list = %(fclfile3)s/%(fclfile2)s/%(fclfile1)s/%(fclfile0)s

job_setup.prescript_2  = sh sbnpoms_wrapperfcl_maker.sh --fclname %(fclfile0)s --wrappername $CONDOR_DIR_INPUT/%(wrapperfclfile0)s
job_setup.prescript_3  = sh sbnpoms_wrapperfcl_maker.sh --fclname %(fclfile1)s --wrappername $CONDOR_DIR_INPUT/%(wrapperfclfile1)s
job_setup.prescript_4  = sh sbnpoms_wrapperfcl_maker.sh --fclname %(fclfile2)s --wrappername $CONDOR_DIR_INPUT/%(wrapperfclfile2)s
job_setup.prescript_5  = sh sbnpoms_wrapperfcl_maker.sh --fclname %(fclfile3)s --wrappername $CONDOR_DIR_INPUT/%(wrapperfclfile3)s

job_setup.prescript_6 = sbnpoms_metadata_injector.sh --inputfclname $CONDOR_DIR_INPUT/%(wrapperfclfile0)s --mdfclname %(fcl_list)s --mdprojectname %(campaign)s --mdprojectstage  %(stage_name)s --mdprojectversion %(version)s --mdprojectsoftware %(experiment)scode --mdproductionname  %(sample)s --mdproductiontype %(prodtype)s --mdappversion %(version)s --mdfiletype %(filetype)s --mdappfamily art --mdruntype physics --mdprojectversion %(version)s --mdgroupname %(experiment)s
job_setup.prescript_7 = sbnpoms_metadata_injector.sh --inputfclname $CONDOR_DIR_INPUT/%(wrapperfclfile1)s --mdfclname %(fcl_list)s --mdprojectname %(campaign)s --mdprojectstage  %(stage_name)s --mdprojectversion %(version)s --mdprojectsoftware %(experiment)scode --mdproductionname  %(sample)s --mdproductiontype %(prodtype)s --mdappversion %(version)s --mdfiletype %(filetype)s --mdappfamily art --mdruntype physics --mdprojectversion %(version)s --mdgroupname %(experiment)s
job_setup.prescript_8 = sbnpoms_metadata_injector.sh --inputfclname $CONDOR_DIR_INPUT/%(wrapperfclfile2)s --mdfclname %(fcl_list)s --mdprojectname %(campaign)s --mdprojectstage  %(stage_name)s --mdprojectversion %(version)s --mdprojectsoftware %(experiment)scode --mdproductionname  %(sample)s --mdproductiontype %(prodtype)s --mdappversion %(version)s --mdfiletype %(filetype)s --mdappfamily art --mdruntype physics --mdprojectversion %(version)s --mdgroupname %(experiment)s
job_setup.prescript_9 = sbnpoms_metadata_injector.sh --inputfclname $CONDOR_DIR_INPUT/%(wrapperfclfile3)s --mdfclname %(fcl_list)s --mdprojectname %(campaign)s --mdprojectstage  %(stage_name)s --mdprojectversion %(version)s --mdprojectsoftware %(experiment)scode --mdproductionname  %(sample)s --mdproductiontype %(prodtype)s --mdappversion %(version)s --mdfiletype %(filetype)s --mdappfamily art --mdruntype physics --mdprojectversion %(version)s --mdgroupname %(experiment)s
job_setup.prescript_10 = echo "This PROCESS is ${PROCESS}"
job_setup.prescript_11 = echo "This JOBSUBJOBSECTION is ${JOBSUBJOBSECTION}"

##Postcripts
job_setup.postscript = echo "=========================="
job_setup.postscript_1 = cat $CONDOR_DIR_INPUT/%(wrapperfclfile0)s
job_setup.postscript_2 = echo "=========================="
job_setup.postscript_3 = cat %(fclfile0)s
job_setup.postscript_4 = echo "=========================="
job_setup.postscript_5 = cat $CONDOR_DIR_INPUT/%(wrapperfclfile1)s
job_setup.postscript_6 = echo "=========================="
job_setup.postscript_7 = cat $CONDOR_DIR_INPUT/%(wrapperfclfile2)s
job_setup.postscript_8 = echo "=========================="
job_setup.postscript_9 = cat $CONDOR_DIR_INPUT/%(wrapperfclfile3)s
job_setup.postscript_10 = echo "=========================="

job_setup.postscript_11 = ls -ltrh
job_setup.postscript_12 = du -h
job_setup.postscript_13 = echo "This PROCESS is ${PROCESS}"
job_setup.postscript_14 = echo "This JOBSUBJOBSECTION is ${JOBSUBJOBSECTION}"

####Executables#####
##stagename0 = detsim
executable.name       = lar
executable.arg_1      = -c
executable.arg_2      = \$CONDOR_DIR_INPUT/%(wrapperfclfile0)s
executable.arg_3      = -o
executable.arg_4      = %(basename)s_%(stagename0)s_\${CLUSTER}_\${JOBSUBJOBSECTION}.root
executable.arg_5      = -T 
executable.arg_6      = hist_%(basename)s_%(stagename0)s_\${CLUSTER}_\${JOBSUBJOBSECTION}.root
executable.arg_7      = -n
executable.arg_8      = %(nevt)s
executable.arg_9      = --sam-data-tier
executable.arg_10     = %(stagename0)s
executable.arg_11     = --sam-stream-name
executable.arg_12     = %(streamname)s
executable.arg_13     = -s
executable.arg_14     = 

##stagename1 = stage0
#reco1/stage0 (change name for lar and leave arg_1 and arg_16-19 empty to not use multithreading)
executable_1.name   = LD_PRELOAD=\\\\\$JEMALLOC_LIB/libjemalloc.so
#executable_1.name = lar
executable_1.arg_1  = lar
executable_1.arg_2  = -c
executable_1.arg_3  = \$CONDOR_DIR_INPUT/%(wrapperfclfile1)s
executable_1.arg_4  = -o
executable_1.arg_5  = %(basename)s_%(stagename1)s_\${CLUSTER}_\${JOBSUBJOBSECTION}.root
executable_1.arg_6  = -T
executable_1.arg_7  = hist_%(basename)s_%(stagename1)s_\${CLUSTER}_\${JOBSUBJOBSECTION}.root
executable_1.arg_8  = -n
executable_1.arg_9  = %(nevt)s
executable_1.arg_10 = --sam-data-tier
executable_1.arg_11 = %(stagename1)s
executable_1.arg_12 = --sam-stream-name
executable_1.arg_13 = %(streamname)s
executable_1.arg_14 = -s
executable_1.arg_15 = %(basename)s_%(stagename0)s_\${CLUSTER}_\${JOBSUBJOBSECTION}.root

#Yes MT
executable_1.arg_16 = --nschedules
executable_1.arg_17 = 1
executable_1.arg_18 = --nthreads
executable_1.arg_19 = 2

#No MT
#executable_1.arg_16 = 
#executable_1.arg_17 = 
#executable_1.arg_18 = 
#executable_1.arg_19 = 


##stagename2 = reco2/stage1
executable_2.name = lar
executable_2.arg_1 = -c
executable_2.arg_2 = \$CONDOR_DIR_INPUT/%(wrapperfclfile2)s
executable_2.arg_3 = -o
executable_2.arg_4 = %(basename)s_%(stagename2)s_\${CLUSTER}_\${JOBSUBJOBSECTION}.root
executable_2.arg_5 = -T
executable_2.arg_6 = calib_ntuples_%(basename)s_%(stagename2)s_\${CLUSTER}_\${JOBSUBJOBSECTION}.root
executable_2.arg_7 = -n
executable_2.arg_8 = %(nevt)s
executable_2.arg_9 = --sam-data-tier
executable_2.arg_10 = simulation
executable_2.arg_11 = --sam-stream-name
executable_2.arg_12 = %(streamname)s
executable_2.arg_13 = -s
executable_2.arg_14 = %(basename)s_%(stagename1)s_\${CLUSTER}_\${JOBSUBJOBSECTION}.root

##stagename3 = caf
executable_3.name       = lar
executable_3.arg_1      = -c
executable_3.arg_2      = \$CONDOR_DIR_INPUT/%(wrapperfclfile3)s
executable_3.arg_3      = -s
executable_3.arg_4      = %(basename)s_%(stagename2)s_\${CLUSTER}_\${JOBSUBJOBSECTION}.root
executable_3.arg_5      = -n
executable_3.arg_6      = %(nevt)s
executable_3.arg_7      =
executable_3.arg_8      =
executable_3.arg_9      =
executable_3.arg_10     = 
executable_3.arg_11     = 
executable_3.arg_12     = 
executable_3.arg_13     = 
executable_3.arg_14     = 

#####job_output######
##stagename0/1/2/3=detsim/stage0/stage1/caf

##stage1 = stagename2
job_output.add_to_dataset = %(dataset_name_struct)s_%(stagename2)s
job_output.metadata_extractor = sam_metadata_dumper
job_output.addoutput = %(basename)s_%(stagename2)s_\${CLUSTER}_\${JOBSUBJOBSECTION}.root
job_output.rename = unique
job_output.filter_metadata_1 = parents
job_output.declare_metadata = True
job_output.add_location = True
job_output.hash = 2
job_output.dest = %(scratch_dest)s/%(stagename2)s/

#filetype = mc
##caf and flatcaf destinations
##caf = stagename3
job_output_1.add_to_dataset = %(dataset_name_struct)s_caf
job_output_1.metadata_extractor = sbnpoms_metadata_extractor.py
job_output_1.addoutput = %(basename)s_%(stagename2)s_\${CLUSTER}_\${JOBSUBJOBSECTION}.caf.root
job_output_1.rename = unique
job_output_1.add_metadata_1 = file_format=caf
job_output_1.add_metadata_2 = file_type=mc
job_output_1.declare_metadata = True
job_output_1.add_location = True
job_output_1.hash = 2
job_output_1.dest  = %(data_dest)s/caf/

job_output_2.add_to_dataset = %(dataset_name_struct)s_flatcaf
job_output_2.metadata_extractor = sbnpoms_metadata_extractor.py
job_output_2.addoutput = %(basename)s_%(stagename2)s_\${CLUSTER}_\${JOBSUBJOBSECTION}.flat.caf.root
job_output_2.rename = unique
job_output_2.add_metadata_1 = file_format=flat_caf
job_output_2.add_metadata_2 = file_type=mc
job_output_2.declare_metadata = True
job_output_2.add_location = True
job_output_2.hash = 2
job_output_2.dest  = %(data_dest)s/flatcaf/

#calib tuples extraction
job_output_3.add_to_dataset = %(dataset_name_struct)s_calibtuple
job_output_3.metadata_extractor = sbnpoms_metadata_extractor.py
job_output_3.addoutput   = calib_ntuples_%(basename)s_%(stagename2)s_\${CLUSTER}_\${JOBSUBJOBSECTION}.root
job_output_3.rename      = unique
job_output_3.declare_metadata = True
job_output_3.add_location = True
job_output_3.add_metadata_1 = file_format=calib_ntuples
job_output_3.add_metadata_2 = file_type=mc
job_output_3.hash 	    = 2
job_output_3.dest  = %(scratch_dest)s/calibtuple/

##stage0 = stagename1
job_output_4.add_to_dataset = %(dataset_name_struct)s_%(stagename1)s
job_output_4.metadata_extractor = sam_metadata_dumper
job_output_4.addoutput = %(basename)s_%(stagename1)s_\${CLUSTER}_\${JOBSUBJOBSECTION}.root
job_output_4.rename = unique
job_output_4.filter_metadata_1 = parents
job_output_4.declare_metadata = True
job_output_4.add_location = True
job_output_4.hash = 2
job_output_4.dest = %(scratch_dest)s/%(stagename1)s/


[stage_stage1_caf]

#submit.tar_file_name     = dropbox:///pnfs/icarus/resilient/icaruspro/GridFiles/mpvmpr_Pi0_MopUp_v09_89_01_01p03.tar
submit.tar_file_name     = dropbox:///pnfs/icarus/resilient/icaruspro/GridFiles/MopUpStudies_v09_89_01_01p02.tar
sam_consumer.limit = 1
job_setup.ifdh_art = False
job_setup.multifile = True
submit.dataset = %(sam_dataset)s
global.basename = %(fclfilename0)s
global.output_filename = %(fclfilename0)s
global.stage_name = %(stagename0)s_%(stagename1)s
global.fcl_list = %(fclfile1)s/%(fclfile0)s

job_setup.prescript_2  = sh sbnpoms_wrapperfcl_maker.sh --fclname %(fclfile0)s --wrappername $CONDOR_DIR_INPUT/%(wrapperfclfile0)s
job_setup.prescript_3  = sh sbnpoms_wrapperfcl_maker.sh --fclname %(fclfile1)s --wrappername $CONDOR_DIR_INPUT/%(wrapperfclfile1)s

job_setup.prescript_4 = sbnpoms_metadata_injector.sh --inputfclname $CONDOR_DIR_INPUT/%(wrapperfclfile0)s --mdfclname %(fcl_list)s --mdprojectname %(campaign)s --mdprojectstage  %(stage_name)s --mdprojectversion %(version)s --mdprojectsoftware %(experiment)scode --mdproductionname  %(sample)s --mdproductiontype %(prodtype)s --mdappversion %(version)s --mdfiletype %(filetype)s --mdappfamily art --mdruntype physics --mdprojectversion %(version)s --mdgroupname %(experiment)s
job_setup.prescript_5 = sbnpoms_metadata_injector.sh --inputfclname $CONDOR_DIR_INPUT/%(wrapperfclfile1)s --mdfclname %(fcl_list)s --mdprojectname %(campaign)s --mdprojectstage  %(stage_name)s --mdprojectversion %(version)s --mdprojectsoftware %(experiment)scode --mdproductionname  %(sample)s --mdproductiontype %(prodtype)s --mdappversion %(version)s --mdfiletype %(filetype)s --mdappfamily art --mdruntype physics --mdprojectversion %(version)s --mdgroupname %(experiment)s
job_setup.prescript_6 = echo "This PROCESS is ${PROCESS}"
job_setup.prescript_7 = echo "This JOBSUBJOBSECTION is ${JOBSUBJOBSECTION}"

##Postcripts
job_setup.postscript = echo "=========================="
job_setup.postscript_1 = cat $CONDOR_DIR_INPUT/%(wrapperfclfile0)s
job_setup.postscript_2 = echo "=========================="
job_setup.postscript_3 = cat %(fclfile0)s
job_setup.postscript_4 = echo "=========================="
job_setup.postscript_5 = cat $CONDOR_DIR_INPUT/%(wrapperfclfile1)s


job_setup.postscript_6 = ls -ltrh
job_setup.postscript_7 = du -h
job_setup.postscript_8 = rootstat.py %(basename)s_%(stagename0)s_\${CLUSTER}_\${JOBSUBJOBSECTION}.root
job_setup.postscript_9 = echo "This PROCESS is ${PROCESS}"
job_setup.postscript_10 = echo "This JOBSUBJOBSECTION is ${JOBSUBJOBSECTION}"

####Executables#####
##stagename0 = reco2/stage1
executable.name = lar
executable.arg_1 = -c
executable.arg_2 = \$CONDOR_DIR_INPUT/%(wrapperfclfile0)s
executable.arg_3 = -o
executable.arg_4 = %(output_filename)s_%(stagename0)s_\${CLUSTER}_\${JOBSUBJOBSECTION}.root
executable.arg_5 = -T
executable.arg_6 = calib_ntuples_%(basename)s_%(stagename0)s_\${CLUSTER}_\${JOBSUBJOBSECTION}.root
executable.arg_7 = -n
executable.arg_8 = %(nevt)s
executable.arg_9 = --sam-data-tier
executable.arg_10 = simulation
executable.arg_11 = --sam-stream-name
executable.arg_12 = %(streamname)s
executable.arg_13 = -s
executable.arg_14 = 

##stagename1 = caf
executable_1.name       = lar
executable_1.arg_1      = -c
executable_1.arg_2      = \$CONDOR_DIR_INPUT/%(wrapperfclfile1)s
executable_1.arg_3      = -s
executable_1.arg_4      = %(output_filename)s_%(stagename0)s_\${CLUSTER}_\${JOBSUBJOBSECTION}.root
executable_1.arg_5      = -n
executable_1.arg_6      = %(nevt)s
executable_1.arg_7      =
executable_1.arg_8      =
executable_1.arg_9      =
executable_1.arg_10     = 
executable_1.arg_11     = 
executable_1.arg_12     = 
executable_1.arg_13     = 
executable_1.arg_14     = 

#####job_output######
##stagename0/1/2/3=detsim/stage0/stage1/caf

##stage1 = stagename2
job_output.add_to_dataset = %(dataset_name_struct)s_%(stagename0)s
job_output.metadata_extractor = sam_metadata_dumper
job_output.addoutput = %(output_filename)s_%(stagename0)s_\${CLUSTER}_\${JOBSUBJOBSECTION}.root
job_output.rename = unique
job_output.filter_metadata_1 = parents
job_output.declare_metadata = True
job_output.add_location = True
job_output.hash = 2
job_output.dest = %(scratch_dest)s/%(stagename0)s/

#filetype = mc
##caf and flatcaf destinations
##caf = stagename3
job_output_1.add_to_dataset = %(dataset_name_struct)s_caf
job_output_1.metadata_extractor = sbnpoms_metadata_extractor.py
job_output_1.addoutput = %(output_filename)s_%(stagename0)s_\${CLUSTER}_\${JOBSUBJOBSECTION}.caf.root
job_output_1.rename = unique
job_output_1.add_metadata_1 = file_format=caf
job_output_1.add_metadata_2 = file_type=mc
job_output_1.declare_metadata = True
job_output_1.add_location = True
job_output_1.hash = 2
job_output_1.dest  = %(data_dest)s/caf/

job_output_2.add_to_dataset = %(dataset_name_struct)s_flatcaf
job_output_2.metadata_extractor = sbnpoms_metadata_extractor.py
job_output_2.addoutput = %(output_filename)s_%(stagename0)s_\${CLUSTER}_\${JOBSUBJOBSECTION}.flat.caf.root
job_output_2.rename = unique
job_output_2.add_metadata_1 = file_format=flat_caf
job_output_2.add_metadata_2 = file_type=mc
job_output_2.declare_metadata = True
job_output_2.add_location = True
job_output_2.hash = 2
job_output_2.dest  = %(data_dest)s/flatcaf/

#calib tuples extraction
job_output_3.add_to_dataset = %(dataset_name_struct)s_calibtuple
job_output_3.metadata_extractor = sbnpoms_metadata_extractor.py
job_output_3.addoutput   = calib_ntuples_%(output_filename)s_%(stagename0)s_\${CLUSTER}_\${JOBSUBJOBSECTION}.root
job_output_3.rename      = unique
job_output_3.declare_metadata = True
job_output_3.add_location = True
job_output_3.add_metadata_1 = file_format=calib_ntuples
job_output_3.add_metadata_2 = file_type=mc
job_output_3.hash 	    = 2
job_output_3.dest  = %(scratch_dest)s/calibtuple/